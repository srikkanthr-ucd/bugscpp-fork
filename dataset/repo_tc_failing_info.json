{
    "cpp_peglib-4": {
        "74": {
            "failing_info": "\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ntest-main is a Catch v2.2.2 host application.\nRun with -? for options\n\n-------------------------------------------------------------------------------\nMacro rule-parameter collision\n-------------------------------------------------------------------------------\n/home/workspace/test/test.cc:1456\n...............................................................................\n\n/home/workspace/test/test.cc:1465: FAILED:\n  REQUIRE( parser.parse(\"c\") )\nwith expansion:\n  false\n\n===============================================================================\ntest cases: 1 | 1 failed\nassertions: 1 | 1 failed",
            "tc_code": "TEST_CASE(\"Macro rule-parameter collision\", \"[macro]\")\n{\n    parser parser(R\"(\n        A    <- B(C)\n        B(D) <- D\n        C    <- 'c'\n        D    <- 'd'\n\t)\");\n\n    REQUIRE(parser.parse(\"c\"));\n}"
        }
    },
    "cppcheck-8": {
        "32": {
            "failing_info": "Internal ctest changing into directory: /home/workspace/build\nTest project /home/workspace/build\n    Start 32: TestOther\n1/1 Test #32: TestOther ........................***Failed    1.51 sec\nTestOther::emptyBrackets\nTestOther::zeroDiv1\nTestOther::zeroDiv2\nTestOther::zeroDiv3\nTestOther::zeroDiv4\nTestOther::zeroDiv5\nTestOther::zeroDiv6\nTestOther::zeroDiv7\nTestOther::zeroDiv8\nTestOther::zeroDiv9\nTestOther::zeroDiv10\nTestOther::zeroDiv11\nTestOther::zeroDiv12\nTestOther::zeroDivCond\nTestOther::nanInArithmeticExpression\nTestOther::varScope1\nTestOther::varScope2\nTestOther::varScope3\nTestOther::varScope4\nTestOther::varScope5\nTestOther::varScope6\nTestOther::varScope7\nTestOther::varScope8\nTestOther::varScope9\nTestOther::varScope10\nTestOther::varScope11\nTestOther::varScope12\nTestOther::varScope13\nTestOther::varScope14\nTestOther::varScope15\nTestOther::varScope16\nTestOther::varScope17\nTestOther::varScope18\nTestOther::varScope20\nTestOther::varScope21\nTestOther::varScope22\nTestOther::varScope23\nTestOther::varScope24\nTestOther::varScope25\nTestOther::varScope26\nTestOther::oldStylePointerCast\nTestOther::invalidPointerCast\nTestOther::passedByValue\nTestOther::passedByValue_nonConst\nTestOther::passedByValue_externC\nTestOther::constVariable\nTestOther::switchRedundantAssignmentTest\nTestOther::switchRedundantOperationTest\nTestOther::switchRedundantBitwiseOperationTest\nTestOther::unreachableCode\nTestOther::suspiciousCase\nTestOther::suspiciousEqualityComparison\nTestOther::selfAssignment\nTestOther::trac1132\nTestOther::testMisusedScopeObjectDoesNotPickFunction1\nTestOther::testMisusedScopeObjectDoesNotPickFunction2\nTestOther::testMisusedScopeObjectPicksClass\nTestOther::testMisusedScopeObjectPicksStruct\nTestOther::testMisusedScopeObjectDoesNotPickIf\nTestOther::testMisusedScopeObjectDoesNotPickConstructorDeclaration\nTestOther::testMisusedScopeObjectDoesNotPickFunctor\nTestOther::testMisusedScopeObjectDoesNotPickLocalClassConstructors\nTestOther::testMisusedScopeObjectDoesNotPickUsedObject\nTestOther::testMisusedScopeObjectDoesNotPickPureC\nTestOther::testMisusedScopeObjectDoesNotPickNestedClass\nTestOther::testMisusedScopeObjectInConstructor\nTestOther::testMisusedScopeObjectNoCodeAfter\nTestOther::trac2071\nTestOther::trac2084\nTestOther::trac3693\nTestOther::clarifyCalculation\nTestOther::clarifyStatement\nTestOther::duplicateBranch\nTestOther::duplicateBranch1\nTestOther::duplicateBranch2\nTestOther::duplicateBranch3\nTestOther::duplicateBranch4\nTestOther::duplicateExpression1\nTestOther::duplicateExpression2\nTestOther::duplicateExpression3\nTestOther::duplicateExpression4\nTestOther::duplicateExpression5\nTestOther::duplicateExpression6\nTestOther::duplicateExpression7\nTestOther::duplicateExpression8\nTestOther::duplicateExpression9\nTestOther::duplicateExpression10\nTestOther::duplicateExpression11\nTestOther::duplicateExpressionLoop\nTestOther::duplicateValueTernary\nTestOther::duplicateExpressionTernary\nTestOther::duplicateExpressionTemplate\nTestOther::oppositeExpression\nTestOther::duplicateVarExpression\nTestOther::duplicateVarExpressionUnique\nTestOther::duplicateVarExpressionAssign\nTestOther::duplicateVarExpressionCrash\nTestOther::multiConditionSameExpression\nTestOther::checkSignOfUnsignedVariable\nTestOther::checkSignOfPointer\nTestOther::checkForSuspiciousSemicolon1\nTestOther::checkForSuspiciousSemicolon2\nTestOther::checkInvalidFree\nTestOther::checkRedundantCopy\nTestOther::checkNegativeShift\nTestOther::incompleteArrayFill\nTestOther::redundantVarAssignment\nTestOther::redundantVarAssignment_trivial\nTestOther::redundantVarAssignment_struct\nTestOther::redundantVarAssignment_7133\nTestOther::redundantVarAssignment_stackoverflow\nTestOther::redundantVarAssignment_lambda\nTestOther::redundantVarAssignment_loop\nTestOther::redundantVarAssignment_after_switch\nTestOther::redundantVarAssignment_pointer\nTestOther::redundantVarAssignment_pointer_parameter\nTestOther::redundantVarAssignment_array\nTestOther::redundantInitialization\nTestOther::redundantMemWrite\nTestOther::varFuncNullUB\nTestOther::checkPipeParameterSize\nTestOther::checkCastIntToCharAndBack\nTestOther::checkCommaSeparatedReturn\nTestOther::checkPassByReference\nTestOther::checkComparisonFunctionIsAlwaysTrueOrFalse\nTestOther::integerOverflow\nTestOther::redundantPointerOp\nTestOther::test_isSameExpression\nTestOther::raceAfterInterlockedDecrement\nTestOther::testUnusedLabel\nTestOther::testEvaluationOrder\nTestOther::testEvaluationOrderSelfAssignment\nTestOther::testEvaluationOrderMacro\nTestOther::testEvaluationOrderSequencePointsFunctionCall\nTestOther::testEvaluationOrderSequencePointsComma\nTestOther::testEvaluationOrderSizeof\nTestOther::testUnsignedLessThanZero\nTestOther::doubleMove1\nTestOther::doubleMoveMemberInitialization1\nTestOther::doubleMoveMemberInitialization2\nTestOther::moveAndAssign1\nTestOther::moveAndAssign2\nTestOther::moveAssignMoveAssign\nTestOther::moveAndReset1\nTestOther::moveAndReset2\nTestOther::moveResetMoveReset\nTestOther::moveAndFunctionParameter\nTestOther::moveAndFunctionParameterReference\nTestOther::moveAndFunctionParameterConstReference\nTestOther::moveAndFunctionParameterUnknown\nTestOther::moveAndReturn\nTestOther::moveAndClear\nTestOther::movedPointer\nTestOther::moveAndAddressOf\nTestOther::partiallyMoved\nTestOther::moveAndLambda\nTestOther::forwardAndUsed\nTestOther::funcArgNamesDifferent\nTestOther::funcArgOrderDifferent\nTestOther::cpp11FunctionArgInit\nTestOther::shadowVariables\nTestOther::constArgument\nTestOther::checkComparePointers\nTestOther::unusedVariableValueTemplate\nTestOther::moduloOfOne\n\n\nTesting Complete\nNumber of tests: 165\nNumber of todos: 11\nTests failed: 1\n\n/home/workspace/test/testother.cpp:1984(TestOther::constVariable): Assertion failed. \nExpected: \n\nActual: \n[test.cpp:1]: (style) Parameter 't' can be declared with const\\n\n\n_____\n\n\n0% tests passed, 1 tests failed out of 1\n\nTotal Test time (real) =   1.56 sec\n\nThe following tests FAILED:\n\t 32 - TestOther (Failed)\nErrors while running CTest\n",
            "tc_code": "   check(\"bool from_string(int& t, const std::string& s) {\\n\"\n              \"    std::istringstream iss(s);\\n\"\n              \"    return !(iss >> t).fail();\\n\"\n              \"}\\n\");\n        ASSERT_EQUALS(\"\", errout.str());"
        }
    },
    "cppcheck-9": {
        "5": {
            "failing_info": "Internal ctest changing into directory: /home/workspace/build\nTest project /home/workspace/build\n    Start 5: TestAutoVariables\n1/1 Test #5: TestAutoVariables ................***Failed    0.63 sec\nTestAutoVariables::testautovar1\nTestAutoVariables::testautovar2\nTestAutoVariables::testautovar3\nTestAutoVariables::testautovar4\nTestAutoVariables::testautovar5\nTestAutoVariables::testautovar6\nTestAutoVariables::testautovar7\nTestAutoVariables::testautovar8\nTestAutoVariables::testautovar9\nTestAutoVariables::testautovar10\nTestAutoVariables::testautovar11\nTestAutoVariables::testautovar12\nTestAutoVariables::testautovar13\nTestAutoVariables::testautovar14\nTestAutoVariables::testautovar15\nTestAutoVariables::testautovar16\nTestAutoVariables::testautovar_array1\nTestAutoVariables::testautovar_array2\nTestAutoVariables::testautovar_normal\nTestAutoVariables::testautovar_ptrptr\nTestAutoVariables::testautovar_return1\nTestAutoVariables::testautovar_return2\nTestAutoVariables::testautovar_return3\nTestAutoVariables::testautovar_return4\nTestAutoVariables::testautovar_extern\nTestAutoVariables::testinvaliddealloc\nTestAutoVariables::testinvaliddealloc_C\nTestAutoVariables::testassign1\nTestAutoVariables::testassign2\nTestAutoVariables::assignAddressOfLocalArrayToGlobalPointer\nTestAutoVariables::assignAddressOfLocalVariableToGlobalPointer\nTestAutoVariables::assignAddressOfLocalVariableToMemberVariable\nTestAutoVariables::returnLocalVariable1\nTestAutoVariables::returnLocalVariable2\nTestAutoVariables::returnLocalVariable3\nTestAutoVariables::returnLocalVariable4\nTestAutoVariables::returnLocalVariable5\nTestAutoVariables::returnLocalVariable6\nTestAutoVariables::returnReference1\nTestAutoVariables::returnReference2\nTestAutoVariables::returnReference3\nTestAutoVariables::returnReference4\nTestAutoVariables::returnReference5\nTestAutoVariables::returnReference6\nTestAutoVariables::returnReference7\nTestAutoVariables::returnReference8\nTestAutoVariables::returnReference9\nTestAutoVariables::returnReference10\nTestAutoVariables::returnReference11\nTestAutoVariables::returnReference12\nTestAutoVariables::returnReference13\nTestAutoVariables::returnReference14\nTestAutoVariables::returnReference15\nTestAutoVariables::returnReference16\nTestAutoVariables::returnReference16\nTestAutoVariables::returnReference17\nTestAutoVariables::returnReference18\nTestAutoVariables::returnReference19\nTestAutoVariables::returnReference20\nTestAutoVariables::returnReferenceFunction\nTestAutoVariables::returnReferenceContainer\nTestAutoVariables::returnReferenceLiteral\nTestAutoVariables::returnReferenceCalculation\nTestAutoVariables::returnReferenceLambda\nTestAutoVariables::returnReferenceInnerScope\nTestAutoVariables::returnReferenceRecursive\nTestAutoVariables::extendedLifetime\nTestAutoVariables::danglingReference\nTestAutoVariables::testglobalnamespace\nTestAutoVariables::returnParameterAddress\nTestAutoVariables::testconstructor\nTestAutoVariables::variableIsUsedInScope\nTestAutoVariables::danglingLifetimeLambda\nTestAutoVariables::danglingLifetimeContainer\nTestAutoVariables::danglingLifetime\nTestAutoVariables::danglingLifetimeFunction\nTestAutoVariables::danglingLifetimeAggegrateConstructor\nTestAutoVariables::danglingLifetimeInitList\nTestAutoVariables::danglingLifetimeImplicitConversion\nTestAutoVariables::danglingTemporaryLifetime\nTestAutoVariables::invalidLifetime\nTestAutoVariables::deadPointer\n\n\nTesting Complete\nNumber of tests: 82\nNumber of todos: 10\nTests failed: 1\n\n/home/workspace/test/testautovariables.cpp:2151(TestAutoVariables::danglingLifetimeContainer): Assertion failed. \nExpected: \n\nActual: \n[test.cpp:4] -> [test.cpp:4]: (error) Reference to local variable returned.\\n\n\n_____\n\n\n0% tests passed, 1 tests failed out of 1\n\nTotal Test time (real) =   0.68 sec\n\nThe following tests FAILED:\n\t  5 - TestAutoVariables (Failed)\nErrors while running CTest\n",
            "tc_code": "        check(\"std::vector<int>* g();\\n\"\n              \"int& f() {\\n\"\n              \"    auto* p = g();\\n\"\n              \"    return p->front();\\n\"\n              \"}\\n\");\n        ASSERT_EQUALS(\"\", errout.str());"
        }
    },
    "cppcheck-11": {
        "60": {
            "failing_info": "Internal ctest changing into directory: /home/workspace/build\nTest project /home/workspace/build\n    Start 60: TestValueFlow\n1/1 Test #60: TestValueFlow ....................***Failed    1.76 sec\nTestValueFlow::valueFlowNumber\nTestValueFlow::valueFlowString\nTestValueFlow::valueFlowPointerAlias\nTestValueFlow::valueFlowLifetime\nTestValueFlow::valueFlowArrayElement\nTestValueFlow::valueFlowMove\nTestValueFlow::valueFlowBitAnd\nTestValueFlow::valueFlowRightShift\nTestValueFlow::valueFlowCalculations\nTestValueFlow::valueFlowSizeof\nTestValueFlow::valueFlowErrorPath\nTestValueFlow::valueFlowBeforeCondition\nTestValueFlow::valueFlowBeforeConditionAndAndOrOrGuard\nTestValueFlow::valueFlowBeforeConditionAssignIncDec\nTestValueFlow::valueFlowBeforeConditionFunctionCall\nTestValueFlow::valueFlowBeforeConditionGlobalVariables\nTestValueFlow::valueFlowBeforeConditionGoto\nTestValueFlow::valueFlowBeforeConditionIfElse\nTestValueFlow::valueFlowBeforeConditionLoop\nTestValueFlow::valueFlowBeforeConditionMacro\nTestValueFlow::valueFlowBeforeConditionSizeof\nTestValueFlow::valueFlowBeforeConditionSwitch\nTestValueFlow::valueFlowBeforeConditionTernaryOp\nTestValueFlow::valueFlowBeforeConditionForward\nTestValueFlow::valueFlowAfterAssign\nTestValueFlow::valueFlowAfterCondition\nTestValueFlow::valueFlowAfterConditionExpr\nTestValueFlow::valueFlowAfterConditionSeveralNot\nTestValueFlow::valueFlowForwardCompoundAssign\nTestValueFlow::valueFlowForwardCorrelatedVariables\nTestValueFlow::valueFlowForwardModifiedVariables\nTestValueFlow::valueFlowForwardFunction\nTestValueFlow::valueFlowForwardTernary\nTestValueFlow::valueFlowForwardLambda\nTestValueFlow::valueFlowForwardTryCatch\nTestValueFlow::valueFlowForwardInconclusiveImpossible\nTestValueFlow::valueFlowFwdAnalysis\nTestValueFlow::valueFlowSwitchVariable\nTestValueFlow::valueFlowForLoop\nTestValueFlow::valueFlowSubFunction\nTestValueFlow::valueFlowFunctionReturn\nTestValueFlow::valueFlowFunctionDefaultParameter\nTestValueFlow::knownValue\nTestValueFlow::valueFlowSizeofForwardDeclaredEnum\nTestValueFlow::valueFlowGlobalVar\nTestValueFlow::valueFlowGlobalConstVar\nTestValueFlow::valueFlowGlobalStaticVar\nTestValueFlow::valueFlowInlineAssembly\nTestValueFlow::valueFlowSameExpression\nTestValueFlow::valueFlowUninit\nTestValueFlow::valueFlowTerminatingCond\nTestValueFlow::valueFlowContainerSize\nTestValueFlow::valueFlowDynamicBufferSize\nTestValueFlow::valueFlowSafeFunctionParameterValues\nTestValueFlow::valueFlowUnknownFunctionReturn\nTestValueFlow::valueFlowPointerAliasDeref\nTestValueFlow::valueFlowCrashIncompleteCode\nTestValueFlow::valueFlowCrash\nTestValueFlow::valueFlowHang\nTestValueFlow::valueFlowCrashConstructorInitialization\nTestValueFlow::valueFlowUnknownMixedOperators\n\n\nTesting Complete\nNumber of tests: 61\nNumber of todos: 15\nTests failed: 1\n\n/home/workspace/test/testvalueflow.cpp:4674(TestValueFlow::valueFlowContainerSize): Assertion failed. \nExpected: \n0\n\nActual: \n1\n\n_____\n\n\n0% tests passed, 1 tests failed out of 1\n\nTotal Test time (real) =   1.81 sec\n\nThe following tests FAILED:\n\t 60 - TestValueFlow (Failed)\nErrors while running CTest\n",
            "tc_code": "code = \"struct Base {\\n\"\n               \"    virtual bool GetString(std::string &) const { return false; }\\n\"\n               \"};\\n\"\n               \"int f() {\\n\"\n               \"    std::string str;\\n\"\n               \"    Base *b = GetClass();\\n\"\n               \"    if (!b->GetString(str)) {\\n\"\n               \"        return -2;\\n\"\n               \"    }\\n\"\n               \"    else {\\n\"\n               \"        return str.front();\\n\"\n               \"    }\\n\"\n               \"}\\n\";\n        ASSERT_EQUALS(0U, tokenValues(code, \"str . front\").size());"
        }
    },
    "cppcheck-25": {
        "5": {
            "failing_info": "Internal ctest changing into directory: /home/workspace/build\nTest project /home/workspace/build\n    Start 5: TestAutoVariables\n1/1 Test #5: TestAutoVariables ................***Failed    0.60 sec\nTestAutoVariables::testautovar1\nTestAutoVariables::testautovar2\nTestAutoVariables::testautovar3\nTestAutoVariables::testautovar4\nTestAutoVariables::testautovar5\nTestAutoVariables::testautovar6\nTestAutoVariables::testautovar7\nTestAutoVariables::testautovar8\nTestAutoVariables::testautovar9\nTestAutoVariables::testautovar10\nTestAutoVariables::testautovar11\nTestAutoVariables::testautovar12\nTestAutoVariables::testautovar13\nTestAutoVariables::testautovar14\nTestAutoVariables::testautovar15\nTestAutoVariables::testautovar16\nTestAutoVariables::testautovar_array1\nTestAutoVariables::testautovar_array2\nTestAutoVariables::testautovar_normal\nTestAutoVariables::testautovar_ptrptr\nTestAutoVariables::testautovar_return1\nTestAutoVariables::testautovar_return2\nTestAutoVariables::testautovar_return3\nTestAutoVariables::testautovar_return4\nTestAutoVariables::testautovar_extern\nTestAutoVariables::testinvaliddealloc\nTestAutoVariables::testinvaliddealloc_C\nTestAutoVariables::testassign1\nTestAutoVariables::testassign2\nTestAutoVariables::assignAddressOfLocalArrayToGlobalPointer\nTestAutoVariables::assignAddressOfLocalVariableToGlobalPointer\nTestAutoVariables::assignAddressOfLocalVariableToMemberVariable\nTestAutoVariables::returnLocalVariable1\nTestAutoVariables::returnLocalVariable2\nTestAutoVariables::returnLocalVariable3\nTestAutoVariables::returnLocalVariable4\nTestAutoVariables::returnLocalVariable5\nTestAutoVariables::returnLocalVariable6\nTestAutoVariables::returnReference1\nTestAutoVariables::returnReference2\nTestAutoVariables::returnReference3\nTestAutoVariables::returnReference4\nTestAutoVariables::returnReference5\nTestAutoVariables::returnReference6\nTestAutoVariables::returnReference7\nTestAutoVariables::returnReference8\nTestAutoVariables::returnReference9\nTestAutoVariables::returnReference10\nTestAutoVariables::returnReference11\nTestAutoVariables::returnReference12\nTestAutoVariables::returnReference13\nTestAutoVariables::returnReference14\nTestAutoVariables::returnReference15\nTestAutoVariables::returnReference16\nTestAutoVariables::returnReference16\nTestAutoVariables::returnReference17\nTestAutoVariables::returnReference18\nTestAutoVariables::returnReference19\nTestAutoVariables::returnReference20\nTestAutoVariables::returnReferenceFunction\nTestAutoVariables::returnReferenceContainer\nTestAutoVariables::returnReferenceLiteral\nTestAutoVariables::returnReferenceCalculation\nTestAutoVariables::returnReferenceLambda\nTestAutoVariables::returnReferenceInnerScope\nTestAutoVariables::returnReferenceRecursive\nTestAutoVariables::extendedLifetime\nTestAutoVariables::danglingReference\nTestAutoVariables::testglobalnamespace\nTestAutoVariables::returnParameterAddress\nTestAutoVariables::testconstructor\nTestAutoVariables::variableIsUsedInScope\nTestAutoVariables::danglingLifetimeLambda\nTestAutoVariables::danglingLifetimeContainer\nTestAutoVariables::danglingLifetime\nTestAutoVariables::danglingLifetimeFunction\nTestAutoVariables::danglingLifetimeAggegrateConstructor\nTestAutoVariables::danglingLifetimeInitList\nTestAutoVariables::danglingLifetimeImplicitConversion\nTestAutoVariables::danglingTemporaryLifetime\nTestAutoVariables::invalidLifetime\nTestAutoVariables::deadPointer\n\n\nTesting Complete\nNumber of tests: 82\nNumber of todos: 10\nTests failed: 1\n\n/home/workspace/test/testautovariables.cpp:2340(TestAutoVariables::danglingLifetime): Assertion failed. \nExpected: \n\nActual: \n[test.cpp:6] -> [test.cpp:5] -> [test.cpp:6]: (error) Returning pointer to local variable 'data' that will be invalid when returning.\\n\n\n_____\n\n\n0% tests passed, 1 tests failed out of 1\n\nTotal Test time (real) =   0.65 sec\n\nThe following tests FAILED:\n\t  5 - TestAutoVariables (Failed)\nErrors while running CTest\n",
            "tc_code": "  check(\"class C {\\n\"\n              \"  std::string f(const char*);\\n\"\n              \"};\\n\"\n              \"std::string C::f(const char*) {\\n\"\n              \"  const char data[] = \\\"x\\\";\\n\"\n              \"  return data;\\n\"\n              \"}\\n\");\n        ASSERT_EQUALS(\"\", errout.str());"
        }
    },
    "exiv2-13": {
        "4": {
            "failing_info": "F\n======================================================================\nFAIL: test_run (test_issue_742.ThrowsWhenSubBoxLengthIsNotGood)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/workspace/tests/system_tests.py\", line 632, in test_run\n    self.compare_stderr(i, command, processed_stderr, stderr)\n  File \"/home/workspace/tests/system_tests.py\", line 755, in compare_stderr\n    msg=\"Standard error does not match\"\n  File \"/home/workspace/tests/system_tests.py\", line 726, in _compare_output\n    expected, got, msg=msg\nAssertionError: 'Uncaught exception: std::bad_alloc\\n' != 'Exiv2 exception in print action for file [64 chars]ta\\n'\n- Uncaught exception: std::bad_alloc\n+ Exiv2 exception in print action for file /home/workspace/test/data/issue_742_poc:\n+ corrupted image metadata\n : Standard error does not match\n\n----------------------------------------------------------------------\nRan 1 test in 0.078s\n\nFAILED (failures=1)\n",
            "tc_code": "ef test_run(self):\n    \"\"\"\n    This function reads in the attributes commands, retval, stdout, stderr,\n    stdin and runs the `expand_variables` function on each. The resulting\n    commands are then run using the subprocess module and compared against the\n    expected values that were provided in the attributes via `compare_stdout`\n    and `compare_stderr`. Furthermore a threading.Timer is used to abort the\n    execution if a configured timeout is reached.\n\n    This function is automatically added as a member function to each system\n    test by the CaseMeta metaclass. This ensures that it is run by each system\n    test **after** setUp() and setUpClass() were run.\n    \"\"\"\n    if not (len(self.commands) == len(self.retval)\n            == len(self.stdout) == len(self.stderr) == len(self.stdin)):\n        raise ValueError(\n            \"commands, retval, stdout, stderr and stdin don't have the same \"\n            \"length\"\n        )\n\n    for i, command, retval, stdout, stderr, stdin in \\\n        zip(range(len(self.commands)),\n            self.commands,\n            self.retval,\n            self.stdout,\n            self.stderr,\n            self.stdin):\n        command, retval, stdout, stderr, stdin = [\n            self.expand_variables(var) for var in\n            (command, retval, stdout, stderr, stdin)\n        ]\n\n        retval = int(retval)\n\n        if \"memcheck\" in _parameters:\n            command = _parameters[\"memcheck\"] + \" \" + command\n\n        if _debug_mode:\n            print(\n                '', \"=\"*80, \"will run: \" + command, \"expected stdout:\", stdout,\n                \"expected stderr:\", stderr,\n                \"expected return value: {:d}\".format(retval),\n                sep='\\n'\n            )\n\n        proc = subprocess.Popen(\n            _cmd_splitter(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE if stdin is not None else None,\n            env=self._get_env(),\n            cwd=self.work_dir,\n            shell=_SUBPROCESS_SHELL\n        )\n\n        # Setup a threading.Timer which will terminate the command if it takes\n        # too long. Don't use the timeout parameter in subprocess.Popen, since\n        # that is not available for all Python 3 versions.\n        # Use a dictionary to indicate a timeout, as booleans get passed by\n        # value and the changes made timeout_reached function will not be\n        # visible once it exits (the command will still be terminated once the\n        # timeout expires).\n        timeout = {\"flag\": False}\n\n        def timeout_reached(tmout):\n            tmout[\"flag\"] = True\n            proc.kill()\n\n        t = threading.Timer(\n            _parameters[\"timeout\"], timeout_reached, args=[timeout]\n        )\n\n        def get_encode_err():\n            \"\"\" Return an error message indicating that the encoding of stdin\n            failed.\n            \"\"\"\n            return \"Could not encode stdin {!s} for the command {!s} with the\"\\\n                \" following encodings: {!s}\"\\\n                .format(stdin, command, ','.join(self.encodings))\n\n        # Prepare stdin: try to encode it or keep it at None if it was not\n        # provided\n        encoded_stdin = None\n        if stdin is not None:\n            encoded_stdin = self._encode(\n                stdin, lambda data_in, encoding: data_in.encode(encoding),\n                get_encode_err\n            )\n\n        if _debug_mode:\n            print('', \"stdin:\", stdin or \"\", sep='\\n')\n\n        t.start()\n        got_stdout, got_stderr = proc.communicate(input=encoded_stdin)\n        t.cancel()\n\n        def get_decode_error():\n            \"\"\" Return an error indicating the the decoding of stdout/stderr\n            failed.\n            \"\"\"\n            return \"Could not decode the output of the command '{!s}' with \"\\\n                \"the following encodings: {!s}\"\\\n                .format(command, ','.join(self.encodings))\n\n        def decode_output(data_in, encoding):\n            \"\"\" Decode stdout/stderr, consider platform dependent line\n            endings.\n            \"\"\"\n            return _process_output_post(data_in.decode(encoding))\n\n        processed_stdout, processed_stderr = [\n            self._encode(output, decode_output, get_decode_error)\n            for output in (got_stdout, got_stderr)\n        ]\n\n        if _debug_mode:\n            print(\n                \"got stdout:\", processed_stdout, \"got stderr:\",\n                processed_stderr, \"got return value: {:d}\"\n                .format(proc.returncode),\n                sep='\\n'\n            )\n\n        self.assertFalse(timeout[\"flag\"], msg=\"Timeout reached\")\n        self.compare_stderr(i, command, processed_stderr, stderr)\n        self.compare_stdout(i, command, processed_stdout, stdout)\n        self.assertEqual(\n            retval, proc.returncode, msg=\"Return value does not match\"\n        )\n\n        self.post_command_hook(i, command)\n\n    self.post_tests_hook()"
        }
    },
    "exiv2-15": {
        "4": {
            "failing_info": "F\n======================================================================\nFAIL: test_run (test_issue_561.ShouldNotThrowsWithSpecificIsoSpeedValue)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/workspace/tests/system_tests.py\", line 635, in test_run\n    retval, proc.returncode, msg=\"Return value does not match\"\nAssertionError: 0 != -11 : Return value does not match\n\n----------------------------------------------------------------------\nRan 1 test in 0.086s\n\nFAILED (failures=1)\n",
            "tc_code": "def test_run(self):\n    \"\"\"\n    This function reads in the attributes commands, retval, stdout, stderr,\n    stdin and runs the `expand_variables` function on each. The resulting\n    commands are then run using the subprocess module and compared against the\n    expected values that were provided in the attributes via `compare_stdout`\n    and `compare_stderr`. Furthermore a threading.Timer is used to abort the\n    execution if a configured timeout is reached.\n\n    This function is automatically added as a member function to each system\n    test by the CaseMeta metaclass. This ensures that it is run by each system\n    test **after** setUp() and setUpClass() were run.\n    \"\"\"\n    if not (len(self.commands) == len(self.retval)\n            == len(self.stdout) == len(self.stderr) == len(self.stdin)):\n        raise ValueError(\n            \"commands, retval, stdout, stderr and stdin don't have the same \"\n            \"length\"\n        )\n\n    for i, command, retval, stdout, stderr, stdin in \\\n        zip(range(len(self.commands)),\n            self.commands,\n            self.retval,\n            self.stdout,\n            self.stderr,\n            self.stdin):\n        command, retval, stdout, stderr, stdin = [\n            self.expand_variables(var) for var in\n            (command, retval, stdout, stderr, stdin)\n        ]\n\n        retval = int(retval)\n\n        if \"memcheck\" in _parameters:\n            command = _parameters[\"memcheck\"] + \" \" + command\n\n        if _debug_mode:\n            print(\n                '', \"=\"*80, \"will run: \" + command, \"expected stdout:\", stdout,\n                \"expected stderr:\", stderr,\n                \"expected return value: {:d}\".format(retval),\n                sep='\\n'\n            )\n\n        proc = subprocess.Popen(\n            _cmd_splitter(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE if stdin is not None else None,\n            env=self._get_env(),\n            cwd=self.work_dir,\n            shell=_SUBPROCESS_SHELL\n        )\n\n        # Setup a threading.Timer which will terminate the command if it takes\n        # too long. Don't use the timeout parameter in subprocess.Popen, since\n        # that is not available for all Python 3 versions.\n        # Use a dictionary to indicate a timeout, as booleans get passed by\n        # value and the changes made timeout_reached function will not be\n        # visible once it exits (the command will still be terminated once the\n        # timeout expires).\n        timeout = {\"flag\": False}\n\n        def timeout_reached(tmout):\n            tmout[\"flag\"] = True\n            proc.kill()\n\n        t = threading.Timer(\n            _parameters[\"timeout\"], timeout_reached, args=[timeout]\n        )\n\n        def get_encode_err():\n            \"\"\" Return an error message indicating that the encoding of stdin\n            failed.\n            \"\"\"\n            return \"Could not encode stdin {!s} for the command {!s} with the\"\\\n                \" following encodings: {!s}\"\\\n                .format(stdin, command, ','.join(self.encodings))\n\n        # Prepare stdin: try to encode it or keep it at None if it was not\n        # provided\n        encoded_stdin = None\n        if stdin is not None:\n            encoded_stdin = self._encode(\n                stdin, lambda data_in, encoding: data_in.encode(encoding),\n                get_encode_err\n            )\n\n        if _debug_mode:\n            print('', \"stdin:\", stdin or \"\", sep='\\n')\n\n        t.start()\n        got_stdout, got_stderr = proc.communicate(input=encoded_stdin)\n        t.cancel()\n\n        def get_decode_error():\n            \"\"\" Return an error indicating the the decoding of stdout/stderr\n            failed.\n            \"\"\"\n            return \"Could not decode the output of the command '{!s}' with \"\\\n                \"the following encodings: {!s}\"\\\n                .format(command, ','.join(self.encodings))\n\n        def decode_output(data_in, encoding):\n            \"\"\" Decode stdout/stderr, consider platform dependent line\n            endings.\n            \"\"\"\n            return _process_output_post(data_in.decode(encoding))\n\n        processed_stdout, processed_stderr = [\n            self._encode(output, decode_output, get_decode_error)\n            for output in (got_stdout, got_stderr)\n        ]\n\n        if _debug_mode:\n            print(\n                \"got stdout:\", processed_stdout, \"got stderr:\",\n                processed_stderr, \"got return value: {:d}\"\n                .format(proc.returncode),\n                sep='\\n'\n            )\n\n        self.assertFalse(timeout[\"flag\"], msg=\"Timeout reached\")\n        self.compare_stderr(i, command, processed_stderr, stderr)\n        self.compare_stdout(i, command, processed_stdout, stdout)\n        self.assertEqual(\n            retval, proc.returncode, msg=\"Return value does not match\"\n        )\n\n        self.post_command_hook(i, command)\n\n    self.post_tests_hook()"
        }
    },
    "exiv2-20": {
        "4": {
            "failing_info": "...............s...F...............................................s........\n======================================================================\nFAIL: test_run (test_issue_1137.MetadataPiping)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/workspace/tests/system_tests.py\", line 653, in test_run\n    self.compare_stdout(i, command, processed_stdout, stdout)\n  File \"/home/workspace/tests/system_tests.py\", line 768, in compare_stdout\n    msg=\"Standard output does not match\"\n  File \"/home/workspace/tests/system_tests.py\", line 746, in _compare_output\n    expected, got, msg=msg\nAssertionError: 'set [40 chars]      N\\nset Exif.GPSInfo.GPSLatitude         [157 chars]/1\\n' != 'set [40 chars]     Ascii      N\\nset Exif.GPSInfo.GPSLatitud[197 chars]/1\\n'\n- set Exif.GPSInfo.GPSLatitudeRef                   N\n+ set Exif.GPSInfo.GPSLatitudeRef                  Ascii      N\n?                                                  ++++++++++\n- set Exif.GPSInfo.GPSLatitude                      51/1 106969/10000 0/1\n+ set Exif.GPSInfo.GPSLatitude                     Rational   51/1 106969/10000 0/1\n?                                                  ++++++++++\n- set Exif.GPSInfo.GPSLongitudeRef                  W\n+ set Exif.GPSInfo.GPSLongitudeRef                 Ascii      W\n?                                                  ++++++++++\n- set Exif.GPSInfo.GPSLongitude                     1/1 495984/10000 0/1\n+ set Exif.GPSInfo.GPSLongitude                    Rational   1/1 495984/10000 0/1\n?                                                  ++++++++++\n : Standard output does not match\n\n----------------------------------------------------------------------\nRan 76 tests in 12.246s\n\nFAILED (failures=1, skipped=2)\n",
            "tc_code": "def test_run(self):\n    if not (len(self.commands) == len(self.retval)\n            == len(self.stdout) == len(self.stderr) == len(self.stdin)):\n        raise ValueError(\n            \"commands, retval, stdout, stderr and stdin don't have the same \"\n            \"length\"\n        )\n\n    for i, command, retval, stdout, stderr, stdin in \\\n        zip(range(len(self.commands)),\n            self.commands,\n            self.retval,\n            self.stdout,\n            self.stderr,\n            self.stdin):\n        command, retval, stdout, stderr, stdin = [\n            self.expand_variables(var) for var in\n            (command, retval, stdout, stderr, stdin)\n        ]\n\n        retval = int(retval)\n\n        if \"memcheck\" in _parameters:\n            command = _parameters[\"memcheck\"] + \" \" + command\n\n        if _debug_mode:\n            print(\n                '', \"=\"*80, \"will run: \" + command, \"expected stdout:\", stdout,\n                \"expected stderr:\", stderr,\n                \"expected return value: {:d}\".format(retval),\n                sep='\\n'\n            )\n\n        proc = subprocess.Popen(\n            command,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE if stdin is not None else None,\n            env=self._get_env(),\n            cwd=self.work_dir,\n            shell=True,\n        )\n\n        # Setup a threading.Timer which will terminate the command if it takes\n        # too long. Don't use the timeout parameter in subprocess.Popen, since\n        # that is not available for all Python 3 versions.\n        # Use a dictionary to indicate a timeout, as booleans get passed by\n        # value and the changes made timeout_reached function will not be\n        # visible once it exits (the command will still be terminated once the\n        # timeout expires).\n        timeout = {\"flag\": False}\n\n        def timeout_reached(tmout):\n            tmout[\"flag\"] = True\n            proc.kill()\n\n        t = threading.Timer(\n            _parameters[\"timeout\"], timeout_reached, args=[timeout]\n        )\n\n        def get_encode_err():\n            \"\"\" Return an error message indicating that the encoding of stdin\n            failed.\n            \"\"\"\n            return \"Could not encode stdin {!s} for the command {!s} with the\"\\\n                \" following encodings: {!s}\"\\\n                .format(stdin, command, ','.join(self.encodings))\n\n        # Prepare stdin: try to encode it or keep it at None if it was not\n        # provided\n        encoded_stdin = None\n        if stdin is not None:\n            encoded_stdin = self._encode(\n                stdin, lambda data_in, encoding: data_in.encode(encoding),\n                get_encode_err\n            )\n\n        if _debug_mode:\n            print('', \"stdin:\", stdin or \"\", sep='\\n')\n\n        t.start()\n        got_stdout, got_stderr = proc.communicate(input=encoded_stdin)\n        t.cancel()\n\n        def get_decode_error():\n            \"\"\" Return an error indicating the the decoding of stdout/stderr\n            failed.\n            \"\"\"\n            return \"Could not decode the output of the command '{!s}' with \"\\\n                \"the following encodings: {!s}\"\\\n                .format(command, ','.join(self.encodings))\n\n        def decode_output(data_in, encoding):\n            \"\"\" Decode stdout/stderr, consider platform dependent line\n            endings.\n            \"\"\"\n            return _process_output_post(data_in.decode(encoding))\n\n        processed_stdout, processed_stderr = [\n            self._encode(output, decode_output, get_decode_error)\n            for output in (got_stdout, got_stderr)\n        ]\n\n        if _debug_mode:\n            print(\n                \"got stdout:\", processed_stdout, \"got stderr:\",\n                processed_stderr, \"got return value: {:d}\"\n                .format(proc.returncode),\n                sep='\\n'\n            )\n\n        self.assertFalse(timeout[\"flag\"], msg=\"Timeout reached\")\n        self.compare_stderr(i, command, processed_stderr, stderr)\n        self.compare_stdout(i, command, processed_stdout, stdout)\n        self.assertEqual(\n            retval, proc.returncode, msg=\"Return value does not match\"\n        )\n\n        self.post_command_hook(i, command)\n\n    self.post_tests_hook()"
        },
        "6": {
            "failing_info": "F\n======================================================================\nFAIL: test_run (test_issue_1969.TestPrintPlainWithSet)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/workspace/tests/system_tests.py\", line 653, in test_run\n    self.compare_stdout(i, command, processed_stdout, stdout)\n  File \"/home/workspace/tests/system_tests.py\", line 768, in compare_stdout\n    msg=\"Standard output does not match\"\n  File \"/home/workspace/tests/system_tests.py\", line 746, in _compare_output\n    expected, got, msg=msg\nAssertionError: 'set  Well it is a smiley that happens to be green\\n' != 'set Exif.Image.ImageDescription              [57 chars]en\\n'\n- set  Well it is a smiley that happens to be green\n+ set Exif.Image.ImageDescription                  Ascii      Well it is a smiley that happens to be green\n : Standard output does not match\n\n----------------------------------------------------------------------\nRan 1 test in 0.042s\n\nFAILED (failures=1)\n",
            "tc_code": "def test_run(self):\n    if not (len(self.commands) == len(self.retval)\n            == len(self.stdout) == len(self.stderr) == len(self.stdin)):\n        raise ValueError(\n            \"commands, retval, stdout, stderr and stdin don't have the same \"\n            \"length\"\n        )\n\n    for i, command, retval, stdout, stderr, stdin in \\\n        zip(range(len(self.commands)),\n            self.commands,\n            self.retval,\n            self.stdout,\n            self.stderr,\n            self.stdin):\n        command, retval, stdout, stderr, stdin = [\n            self.expand_variables(var) for var in\n            (command, retval, stdout, stderr, stdin)\n        ]\n\n        retval = int(retval)\n\n        if \"memcheck\" in _parameters:\n            command = _parameters[\"memcheck\"] + \" \" + command\n\n        if _debug_mode:\n            print(\n                '', \"=\"*80, \"will run: \" + command, \"expected stdout:\", stdout,\n                \"expected stderr:\", stderr,\n                \"expected return value: {:d}\".format(retval),\n                sep='\\n'\n            )\n\n        proc = subprocess.Popen(\n            command,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE if stdin is not None else None,\n            env=self._get_env(),\n            cwd=self.work_dir,\n            shell=True,\n        )\n\n        # Setup a threading.Timer which will terminate the command if it takes\n        # too long. Don't use the timeout parameter in subprocess.Popen, since\n        # that is not available for all Python 3 versions.\n        # Use a dictionary to indicate a timeout, as booleans get passed by\n        # value and the changes made timeout_reached function will not be\n        # visible once it exits (the command will still be terminated once the\n        # timeout expires).\n        timeout = {\"flag\": False}\n\n        def timeout_reached(tmout):\n            tmout[\"flag\"] = True\n            proc.kill()\n\n        t = threading.Timer(\n            _parameters[\"timeout\"], timeout_reached, args=[timeout]\n        )\n\n        def get_encode_err():\n            \"\"\" Return an error message indicating that the encoding of stdin\n            failed.\n            \"\"\"\n            return \"Could not encode stdin {!s} for the command {!s} with the\"\\\n                \" following encodings: {!s}\"\\\n                .format(stdin, command, ','.join(self.encodings))\n\n        # Prepare stdin: try to encode it or keep it at None if it was not\n        # provided\n        encoded_stdin = None\n        if stdin is not None:\n            encoded_stdin = self._encode(\n                stdin, lambda data_in, encoding: data_in.encode(encoding),\n                get_encode_err\n            )\n\n        if _debug_mode:\n            print('', \"stdin:\", stdin or \"\", sep='\\n')\n\n        t.start()\n        got_stdout, got_stderr = proc.communicate(input=encoded_stdin)\n        t.cancel()\n\n        def get_decode_error():\n            \"\"\" Return an error indicating the the decoding of stdout/stderr\n            failed.\n            \"\"\"\n            return \"Could not decode the output of the command '{!s}' with \"\\\n                \"the following encodings: {!s}\"\\\n                .format(command, ','.join(self.encodings))\n\n        def decode_output(data_in, encoding):\n            \"\"\" Decode stdout/stderr, consider platform dependent line\n            endings.\n            \"\"\"\n            return _process_output_post(data_in.decode(encoding))\n\n        processed_stdout, processed_stderr = [\n            self._encode(output, decode_output, get_decode_error)\n            for output in (got_stdout, got_stderr)\n        ]\n\n        if _debug_mode:\n            print(\n                \"got stdout:\", processed_stdout, \"got stderr:\",\n                processed_stderr, \"got return value: {:d}\"\n                .format(proc.returncode),\n                sep='\\n'\n            )\n\n        self.assertFalse(timeout[\"flag\"], msg=\"Timeout reached\")\n        self.compare_stderr(i, command, processed_stderr, stderr)\n        self.compare_stdout(i, command, processed_stdout, stdout)\n        self.assertEqual(\n            retval, proc.returncode, msg=\"Return value does not match\"\n        )\n\n        self.post_command_hook(i, command)\n\n    self.post_tests_hook()"
        }
    },
    "openssl-14": {
        "65": {
            "failing_info": "make depend && make _tests\nmake[1]: Entering directory '/home/workspace'\nmake[1]: Leaving directory '/home/workspace'\nmake[1]: Entering directory '/home/workspace'\n( SRCTOP=. \\\n  BLDTOP=. \\\n  PERL=\"/usr/bin/perl\" \\\n  FIPSKEY=\"f4556650ac31d35461610bac4ed81b1a181b2d8a43ea2854cbae22ca74560813\" \\\n  EXE_EXT= \\\n  /usr/bin/perl ./test/run_tests.pl test_ecdsa )\n\n        # INFO:  @ test/ecdsatest.c:241\n        # testing ECDSA for curve secp112r1 as EC key type\n../../util/wrap.pl ../../test/ecdsatest => 139\nnot ok 1 - running ecdsatest\n# ------------------------------------------------------------------------------\n#   Failed test 'running ecdsatest'\n#   at /home/workspace/util/perl/OpenSSL/Test/Simple.pm line 77.\n# Looks like you failed 1 test of 1.15-test_ecdsa.t .. \nDubious, test returned 1 (wstat 256, 0x100)\nFailed 1/1 subtests \n\nTest Summary Report\n-------------------\n15-test_ecdsa.t (Wstat: 256 Tests: 1 Failed: 1)\n  Failed test:  1\n  Non-zero exit status: 1\nFiles=1, Tests=1,  1 wallclock secs ( 0.01 usr  0.00 sys +  0.10 cusr  0.02 csys =  0.13 CPU)\nResult: FAIL\nMakefile:3197: recipe for target '_tests' failed\nmake[1]: *** [_tests] Error 1\nmake[1]: Leaving directory '/home/workspace'\nMakefile:3195: recipe for target 'tests' failed\nmake: *** [tests] Error 2\n",
            "tc_code": "# args:\n#  name\t\t\t(used with setup())\n#  algorithm\t\t(used to check if it's at all supported)\n#  name of binary\t(the program that does the actual test)\nsub simple_test {\n    my ($name, $prgr, @algos) = @_;\n\n    setup($name);\n\n    if (scalar(disabled(@algos))) {\n\tif (scalar(@algos) == 1) {\n\t    plan skip_all => $algos[0].\" is not supported by this OpenSSL build\";\n\t} else {\n\t    my $last = pop @algos;\n\t    plan skip_all => join(\", \", @algos).\" and $last are not supported by this OpenSSL build\";\n\t}\n    }\n\n    plan tests => 1;\n\n    ok(run(test([$prgr])), \"running $prgr\");\n}"
        }
    },
    "openssl-24": {
        "111": {
            "failing_info": "make depend && make _tests\nmake[1]: Entering directory '/home/workspace'\nmake[1]: Leaving directory '/home/workspace'\nmake[1]: Entering directory '/home/workspace'\n( SRCTOP=. \\\n  BLDTOP=. \\\n  PERL=\"/usr/bin/perl\" \\\n  FIPSKEY=\"f4556650ac31d35461610bac4ed81b1a181b2d8a43ea2854cbae22ca74560813\" \\\n  EXE_EXT= \\\n  /usr/bin/perl ./test/run_tests.pl test_evp_extra )\n\n    # ERROR: (ptr) 'pkey_dec = d2i_PKCS8PrivateKey_bio(enc_bio, NULL, NULL, (void *)pwd) != NULL' failed @ test/evp_extra_test2.c:315\n    # 0x0\n    # 808B14F8E77F0000:error:068000A8:asn1 encoding routines:asn1_check_tlen:wrong tag:crypto/asn1/tasn_dec.c:1156:\n    # 808B14F8E77F0000:error:0688010A:asn1 encoding routines:asn1_item_embed_d2i:nested asn1 error:crypto/asn1/tasn_dec.c:322:Type=X509_ALGOR\n    # 808B14F8E77F0000:error:0688010A:asn1 encoding routines:asn1_template_noexp_d2i:nested asn1 error:crypto/asn1/tasn_dec.c:653:Field=algor, Type=X509_SIG\n    # OPENSSL_TEST_RAND_ORDER=1710228668\n    not ok 8 - test_pkcs8key_nid_bio\n# ------------------------------------------------------------------------------\n../../util/wrap.pl ../../test/evp_extra_test2 => 1\nnot ok 3 - running evp_extra_test2\n# ------------------------------------------------------------------------------\n#   Failed test 'running evp_extra_test2'\n#   at test/recipes/30-test_evp_extra.t line 24.\n# Looks like you failed 1 test of 3.30-test_evp_extra.t .. \nDubious, test returned 1 (wstat 256, 0x100)\nFailed 1/3 subtests \n\nTest Summary Report\n-------------------\n30-test_evp_extra.t (Wstat: 256 Tests: 3 Failed: 1)\n  Failed test:  3\n  Non-zero exit status: 1\nFiles=1, Tests=3,  1 wallclock secs ( 0.02 usr  0.00 sys +  1.32 cusr  0.03 csys =  1.37 CPU)\nResult: FAIL\nMakefile:3210: recipe for target '_tests' failed\nmake[1]: *** [_tests] Error 1\nmake[1]: Leaving directory '/home/workspace'\nMakefile:3208: recipe for target 'tests' failed\nmake: *** [tests] Error 2\n",
            "tc_code": "#! /usr/bin/env perl\n# Copyright 2015-2021 The OpenSSL Project Authors. All Rights Reserved.\n#\n# Licensed under the Apache License 2.0 (the \"License\").  You may not use\n# this file except in compliance with the License.  You can obtain a copy\n# in the file LICENSE in the source distribution or at\n# https://www.openssl.org/source/license.html\n\n\nuse strict;\nuse warnings;\n\nuse OpenSSL::Test qw/:DEFAULT bldtop_dir/;\n\nsetup(\"test_evp_extra\");\n\nplan tests => 3;\n\nok(run(test([\"evp_extra_test\"])), \"running evp_extra_test\");\n\n# Run tests with a non-default library context\nok(run(test([\"evp_extra_test\", \"-context\"])), \"running evp_extra_test with a non-default library context\");\n\nok(run(test([\"evp_extra_test2\"])), \"running evp_extra_test2\");\n"
        }
    },
    "yara-1": {
        "55": {
            "failing_info": "expecting ERROR_CALLBACK_REQUIRED (14), got: 0\nFAIL test-api (exit status: 1)",
            "tc_code": "void test_issue_920()\n{\n  const char* rules_str = \"\\\n      rule test { \\\n        condition: true \\\n      }\";\n\n  YR_COMPILER* compiler = NULL;\n\n  yr_initialize();\n\n  if (yr_compiler_create(&compiler) != ERROR_SUCCESS)\n  {\n    perror(\"yr_compiler_create\");\n    exit(EXIT_FAILURE);\n  }\n\n  // Define a variable named \"test\"\n  yr_compiler_define_boolean_variable(compiler, \"test\", 1);\n\n  // The compilation should not succeed, as the rule is named \"test\" and a\n  // a variable with the same name already exists.\n  yr_compiler_add_string(compiler, rules_str, NULL);\n\n  if (compiler->last_error != ERROR_DUPLICATED_IDENTIFIER)\n  {\n    yr_compiler_destroy(compiler);\n    printf(\"expecting ERROR_CALLBACK_REQUIRED (%d), got: %d\\n\",\n           ERROR_DUPLICATED_IDENTIFIER, compiler->last_error);\n    exit(EXIT_FAILURE);\n  }\n\n  yr_compiler_destroy(compiler);\n  yr_finalize();\n}"
        }
    },
    "yara-2": {
        "232": {
            "failing_info": "tests/test-rules.c:1420: rule matches (but shouldn't)\nFAIL test-rules (exit status: 1)",
            "tc_code": "  assert_false_rule_blob(\n       \"rule test { strings: $a = \\\" cmd.exe \\\" nocase wide condition: $a }\",\n       ISSUE_1006);"
        }
    },
    "dlt_daemon-1": {
        "56": {
            "failing_info": "*** stack smashing detected ***: <unknown> terminated\n",
            "tc_code": ""
        }
    },
    "yaml_cpp-6": {
        "10": {
            "failing_info": "Note: Google Test filter = NodeTest.SpecialFlow\n[==========] Running 1 test from 1 test suite.\n[----------] Global test environment set-up.\n[----------] 1 test from NodeTest\n[ RUN      ] NodeTest.SpecialFlow\n/home/workspace/test/integration/load_node_test.cpp:299: Failure\nExpected equality of these values:\n  test.expected_content\n    Which is: \"key: value\"\n  std::string(emitter.c_str())\n    Which is: \"\\\"key\\\\t\\\": \\\"value\\\\t\\\"\"\n/home/workspace/test/integration/load_node_test.cpp:299: Failure\nExpected equality of these values:\n  test.expected_content\n    Which is: \"key: value\"\n  std::string(emitter.c_str())\n    Which is: \"\\\"key\\\\t\\\": \\\"value\\\\t\\\"\"\n/home/workspace/test/integration/load_node_test.cpp:299: Failure\nExpected equality of these values:\n  test.expected_content\n    Which is: \"{key: value}\"\n  std::string(emitter.c_str())\n    Which is: \"{\\\"key\\\\t\\\": \\\"value\\\\t\\\"}\"\n/home/workspace/test/integration/load_node_test.cpp:299: Failure\nExpected equality of these values:\n  test.expected_content\n    Which is: \"{key: value}\"\n  std::string(emitter.c_str())\n    Which is: \"{\\\"key\\\\t\\\": \\\"value\\\\t\\\"}\"\n[  FAILED  ] NodeTest.SpecialFlow (2 ms)\n[----------] 1 test from NodeTest (2 ms total)\n\n[----------] Global test environment tear-down\n[==========] 1 test from 1 test suite ran. (2 ms total)\n[  PASSED  ] 0 tests.\n[  FAILED  ] 1 test, listed below:\n[  FAILED  ] NodeTest.SpecialFlow\n\n 1 FAILED TEST\n",
            "tc_code": "TEST(NodeTest, SpecialFlow) {\n  std::vector<SingleNodeTestCase> tests = {\n      {\"[:]\", NodeType::Sequence, 1, \"[{~: ~}]\"},\n      {\"[a:]\", NodeType::Sequence, 1, \"[{a: ~}]\"},\n      {\"[:a]\", NodeType::Sequence, 1, \"[:a]\"},\n      {\"[,]\", NodeType::Sequence, 1, \"[~]\"},\n      {\"[a:,]\", NodeType::Sequence, 1, \"[{a: ~}]\"},\n      {\"{:}\", NodeType::Map, 1, \"{~: ~}\"},\n      {\"{a:}\", NodeType::Map, 1, \"{a: ~}\"},\n      {\"{:a}\", NodeType::Map, 1, \"{:a: ~}\"},\n      {\"{,}\", NodeType::Map, 1, \"{~: ~}\"},\n      {\"{a:,}\", NodeType::Map, 1, \"{a: ~}\"},\n      //testcase for the trailing TAB of scalar\n      {\"key\\t: value\\t\", NodeType::Map, 1, \"key: value\"},\n      {\"key\\t: value\\t #comment\", NodeType::Map, 1, \"key: value\"},\n      {\"{key\\t: value\\t}\", NodeType::Map, 1, \"{key: value}\"},\n      {\"{key\\t: value\\t #comment\\n}\", NodeType::Map, 1, \"{key: value}\"},\n  };\n  for (const SingleNodeTestCase& test : tests) {\n    Node node = Load(test.input);\n    Emitter emitter;\n    emitter << node;\n    EXPECT_EQ(test.nodeType, node.Type());\n    EXPECT_EQ(test.nodeSize, node.size());\n    EXPECT_EQ(test.expected_content, std::string(emitter.c_str()));\n  }\n}"
        }
    },
    "ndpi-1": {
        "110": {
            "failing_info": "1c1\n< Microsoft\t6\t7205\t1\n---\n> TLS\t6\t7205\t1\n7c7\n< \t1\tTCP 10.0.0.1:31337 <-> 213.199.149.251:443 [proto: 91.212/TLS.Microsoft][cat: Web/5][1 pkts/181 bytes <-> 5 pkts/7024 bytes][Goodput ratio: 70/96][< 1 sec][bytes ratio: -0.950 (Download)][IAT c2s/s2c min/avg/max/stddev: 0/0 0/0 0/0 0/0][Pkt Len c2s/s2c min/avg/max/stddev: 181/968 181/1405 181/1514 0/218][Risk: ** Obsolete TLS version (< 1.1) **** Weak TLS cipher **** TLS Expired Certificate **][TLSv1][Client: ads1.msads.net][ServerNames: *.vo.msecnd.net,*.officeapps.live.com,*.msads.net,*.ads2.msads.net,*.stc.s-msn.com,cdn.dc2files.*.livefilestore-int.com,cdn.*.livefilestore.com,*.marketplace.windowsmobile.com,*.marketplace.windowsmobile-int.com,*.marketplace.windowsmobile-perf.com,*.stj.s-msn.com,ajax.microsoft.com,*.microsoft-sbs-domains.com,*.live.net,*.msn.com,*.msn-int.com,*.f1ds.shared.live-int.com,*.f1ds.wlxrs-int.com,*.shared.live-int.com,*.shared.live.com,*.microsoft.com,*.live.com,*.live-int.com,*.wlxrs.com,*.wlxrs-int.com,*.st.s-msn.com,*.stb.s-msn.com,images.moxy.windowsphone-int.com,*.wlxrsu-int.com,images.partner.windowsphone-int.com,images.partner.windowsphone.com,*.jp.msn.com,*.c3scs.jp.msn.com,*.aspnetcdn.com,*.hotmail.com,*.partner-df.windowsphone-int.com,*.s-msn.com,*.live-int.net,*.windowsphone-int.com,*.windowsphone.com,*.partner-pc.windowsphone-int.com,*.manage.microsoft.com][JA3S: 18e962e106761869a61045bed0e81c2c (WEAK)][Issuer: CN=Microsoft Secure Server Authority][Subject: C=US, L=Redmond, O=Microsoft, OU=GFS, CN=*.officeapps.live.com, CN=*.msads.net, CN=*.ads2.msads.net, CN=*.stc.s-msn.com, CN=cdn.dc2files.*.livefilestore-int.com, CN=cdn.*.livefilestore.com, CN=*.marketplace.windowsmobile.com, CN=*.marketplace.windowsmobile-int.com, CN=*.marketplace.windowsmobile-perf.com, CN=*.stj.s-msn.com, CN=ajax.microsoft.com, CN=*.microsoft-sbs-domains.com, CN=*.live.net, CN=*.msn.com, CN=*.msn-int.com, CN=*.f1ds.shared.live-int.com, CN=*.f1ds.wlxrs-int.com, CN=*.shared.live-int.com, CN=*.shared.live.com, CN=*.microsoft.com, CN=*.live.com, CN=*.live-int.com, CN=*.wlxrs.com, CN=*.wlxrs-int.com, CN=*.st.s-msn.com, CN=*.stb.s-msn.com, CN=images.moxy.windowsphone-int.com, CN=*.wlxrsu-int.com, CN=images.partner.windowsphone-int.com, CN=images.partner.windowsphone.com, CN=*.jp.msn.com, CN=*.c3scs.jp.msn.com, CN=*.aspnetcdn.com, CN=*.hotmail.com, CN=*.partner-df.windowsphone-int.com, CN=*.s-msn.com, CN=*.live-int.net, CN=*.windowsphone-int.com, CN=*.windowsphone.com, CN=*.partner-pc.windowsphone-int.com, CN=*.manage.microsoft.com, CN=*.vo.msecnd.net][Certificate SHA-1: FF:BF:9A:69:8F:C8:44:FF:89:F2:61:49:A7:D1:9A:98:DE:32:84:3B][Validity: 2011-10-21 16:42:03 - 2013-10-20 16:42:03][Cipher: TLS_RSA_WITH_AES_128_CBC_SHA]\n---\n> \t1\tTCP 10.0.0.1:31337 <-> 213.199.149.251:443 [proto: 91/TLS][cat: Web/5][1 pkts/181 bytes <-> 5 pkts/7024 bytes][Goodput ratio: 70/96][< 1 sec][bytes ratio: -0.950 (Download)][IAT c2s/s2c min/avg/max/stddev: 0/0 0/0 0/0 0/0][Pkt Len c2s/s2c min/avg/max/stddev: 181/968 181/1405 181/1514 0/218][Risk: ** Obsolete TLS version (< 1.1) **** Weak TLS cipher **** TLS Expired Certificate **][TLSv1][Client: ads1.msads.net][JA3S: 18e962e106761869a61045bed0e81c2c (WEAK)][Issuer: CN=Microsoft Secure Server Authority][Subject: C=US, L=Redmond, O=Microsoft, OU=GFS, CN=*.officeapps.live.com, CN=*.msads.net, CN=*.ads2.msads.net, CN=*.stc.s-msn.com, CN=cdn.dc2files.*.livefilestore-int.com, CN=cdn.*.livefilestore.com, CN=*.marketplace.windowsmobile.com, CN=*.marketplace.windowsmobile-int.com, CN=*.marketplace.windowsmobile-perf.com, CN=*.stj.s-msn.com, CN=ajax.microsoft.com, CN=*.microsoft-sbs-domains.com, CN=*.live.net, CN=*.msn.com, CN=*.msn-int.com, CN=*.f1ds.shared.live-int.com, CN=*.f1ds.wlxrs-int.com, CN=*.shared.live-int.com, CN=*.shared.live.com, CN=*.microsoft.com, CN=*.live.com, CN=*.live-int.com, CN=*.wlxrs.com, CN=*.wlxrs-int.com, CN=*.st.s-msn.com, CN=*.stb.s-msn.com, CN=images.moxy.windowsphone-int.com, CN=*.wlxrsu-int.com, CN=images.partner.windowsphone-int.com, CN=images.partner.windowsphone.com, CN=*.jp.msn.com, CN=*.c3scs.jp.msn.com, CN=*.aspnetcdn.com, CN=*.hotmail.com, CN=*.partner-df.windowsphone-int.com, CN=*.s-msn.com, CN=*.live-int.net, CN=*.windowsphone-int.com, CN=*.windowsphone.com, CN=*.partner-pc.windowspho][Certificate SHA-1: FF:BF:9A:69:8F:C8:44:FF:89:F2:61:49:A7:D1:9A:98:DE:32:84:3B][Validity: 2011-10-21 16:42:03 - 2013-10-20 16:42:03][Cipher: TLS_RSA_WITH_AES_128_CBC_SHA]\n",
            "tc_code": ""
        }
    },
    "libtiff-1": {
        "82": {
            "failing_info": "TIFFReadDirectoryCheckOrder: Warning, Invalid TIFF directory; tags are not sorted in ascending order.\n.dpp/CVE-2016-5321.tif: Warning, Nonstandard tile length 1, convert file.\nTIFFReadDirectory: Warning, Unknown field with tag 406 (0x196) encountered.\nTIFFFetchNormalTag: Warning, ASCII value for tag \"DocumentName\" contains null byte in value; value incorrectly truncated during reading due to implementation limitations.\nTIFFFetchNormalTag: Warning, IO error during reading of \"YResolution\"; tag ignored.\nTIFFFetchNormalTag: Warning, incorrect count for field \"PageNumber\", expected 2, got 514.\nTIFFReadDirectory: Warning, TIFF directory is missing required \"StripByteCounts\" field, calculating from imagelength.\nTIFFAdvanceDirectory: Error fetching directory count.\n",
            "tc_code": ""
        }
    },
    "libtiff-2": {
        "82": {
            "failing_info": "*** buffer overflow detected ***: terminated\n",
            "tc_code": ""
        }
    },
    "libtiff-3": {
        "82": {
            "failing_info": "TIFFScanlineSize64: Invalid YCbCr subsampling.\nbash: line 1:    19 Floating point exceptiontools/rgb2ycbcr -c zip -r 0 -v 4 -h 0 test/images/logluv-3c-16b.tiff /tmp/temp.tif\n",
            "tc_code": ""
        }
    },
    "libtiff-4": {
        "82": {
            "failing_info": "TIFFReadDirectoryCheckOrder: Warning, Invalid TIFF directory; tags are not sorted in ascending order.\nTIFFReadDirectory: Warning, Unknown field with tag 65535 (0xffff) encountered.\n.dpp/00123-libtiff-fpe-JPEGSetupEncode: Warning, Nonstandard tile width 3, convert file.\nTIFFFetchNormalTag: Warning, IO error during reading of \"DocumentName\"; tag ignored.\nTIFFFetchNormalTag: Warning, Incorrect count for \"XResolution\"; tag ignored.\nTIFFFetchNormalTag: Warning, Incorrect count for \"YResolution\"; tag ignored.\nTIFFFetchNormalTag: Warning, IO error during reading of \"Software\"; tag ignored.\nTIFFFillTile: 0: Invalid tile byte count, tile 1.\nJPEGLib: Not a JPEG file: starts with 0x49 0x49.\nTIFFFillTile: 0: Invalid tile byte count, tile 3.\nTIFFFillTile: 0: Invalid tile byte count, tile 4.\nTIFFFillTile: 0: Invalid tile byte count, tile 5.\nTIFFFillTile: 0: Invalid tile byte count, tile 6.\nJPEGLib: Not a JPEG file: starts with 0x49 0x49.\nTIFFFillTile: 0: Invalid tile byte count, tile 9.\nTIFFFillTile: 0: Invalid tile byte count, tile 10.\nTIFFFillTile: 0: Invalid tile byte count, tile 11.\nJPEGLib: Not a JPEG file: starts with 0x49 0x49.\nbash: line 1:    19 Floating point exceptiontools/tiffcp -i .dpp/00123-libtiff-fpe-JPEGSetupEncode /tmp/foo\n",
            "tc_code": ""
        }
    },
    "libtiff-5": {
        "82": {
            "failing_info": "TIFFReadDirectoryCheckOrder: Warning, Invalid TIFF directory; tags are not sorted in ascending order.\nTIFFReadDirectory: Warning, Unknown field with tag 12336 (0x3030) encountered.\n",
            "tc_code": ""
        }
    },
    "berry-1": {
        "2": {
            "failing_info": "assert_failed: assert failed!\nstack traceback:\n\t<native>: in native function\n\ttests/bitwise.be:13: in function `main`\n",
            "tc_code": "# and, or, xor\na = 11\nassert(a & 0xFE == 10)\nassert(a | 32 == 43)\nassert(a ^ 33 == 42)\n\n# same with literal\nassert(11 & 0xFE == 10)\nassert(11 | 32 == 43)\nassert(11 ^ 33 == 42)\n\n# flip\nassert(~a == -12)\nassert(~11 == -12)\n"
        }
    },
    "berry-2": {
        "3": {
            "failing_info": "assert_failed: assert failed!\nstack traceback:\n\t<native>: in native function\n\ttests/bool.be:25: in function `main`\n",
            "tc_code": "# test cases for boolean expressions\n\nassert(1 != false && 1 != true)\nassert(0 != false && 0 != true)\nassert(!!1 == true)\nassert(!!0 == false)\n\na = true\nb = false\nassert(!!list == true)\nassert(a && b == false)\nassert(!(a && b))\ndef test(a, b)\n    while !(a && b)\n        assert(false)\n    end\nend\ntest(true, true)\n\n# bug in unary \ndef f(i)\n    var j = !i       # bug if i is erroneously modified\n    return i\nend\nassert(f(1) == 1)\n"
        }
    },
    "berry-3": {
        "8": {
            "failing_info": "syntax_error: tests/class_const.be:97: register overflow (more than 255)\n",
            "tc_code": "def assert_attribute_error(f)\n    try\n        f()\n        assert(false, 'unexpected execution flow')\n    except .. as e, m\n        assert(e == 'attribute_error')\n    end\nend\n\nclass A\n    static a\n    def init() self.b = 2 end\n    def f() end \n    var b \n    static c, s, r\nend\n\nassert(A.a == nil)\nassert(A.c == nil)\nassert(A.s == nil)\nassert_attribute_error(/-> A.b)\nassert_attribute_error(/-> A.d)\n\na = A()\nassert(a.b == 2)\nassert(a.a == nil)\nassert(a.c == nil)\n\nA.a = 1\nA.c = 3\nA.s = \"foo\"\nA.r = 3.5\nassert(a.a == 1)\nassert(a.c == 3)\nassert(A.a == 1)\nassert(A.c == 3)\nimport gc gc.collect()\nassert(A.s == \"foo\")\nassert(a.s == \"foo\")\nassert(A.r == 3.5)\nassert(a.r == 3.5)\n\n#- test valid or invalid methods and members -#\n\ndef assert_attribute_error(c)\n    try\n        compile(c)()\n        assert(false, 'unexpected execution flow')\n    except .. as e, m\n        assert(e == 'attribute_error')\n    end\nend\n\nclass A\n    var a, g\n    static h\n    def init() self.a = 1 end\n    def f(x, y) return type(self) end\nend\na=A()\na.g = def (x, y) return type(x) end\nA.h = def (x, y) return type(x) end\n\nassert(type(a.g) == 'function')\nassert(type(a.h) == 'function')\n\nassert_attribute_error(\"a.g(1,2)\")\nassert(a.h(1) == 'instance')\n# A.h(1) - error\n\n#- test static initializers -#\nclass A\n    static a = 1, b, c = 3.5, d = 42, e = \"foo\", f = [1], g = {}\n    var aa,ab\nend\n\nassert(A.a == 1)\nassert(A.b == nil)\nassert(A.c == 3.5)\nassert(A.d == 42)\nassert(A.e == \"foo\")\nassert(A.f == [1])\n\na = A()\nassert(a.a == 1)\nassert(a.b == nil)\nassert(a.c == 3.5)\nassert(a.d == 42)\nassert(a.e == \"foo\")\nassert(a.f == [1])\nassert(a.g == A.g)\nassert(a.aa == nil)\nassert(a.ab == nil)\n\n#- used to fail for subclasses -#\nclass A static a=1 end\nclass B:A static a=A def f() end static b=1 static c=A end\nassert(A.a == 1)\nassert(B.a == A)\nassert(B.b == 1)\nassert(B.c == A)\n"
        }
    },
    "berry-4": {
        "22": {
            "failing_info": "runtime_error: bad argument #2 to 'format': no value\nstack traceback:\n\t<native>: in native function\n\ttests/string.be:32: in function `main`\n",
            "tc_code": "import string as s\n\nassert(s.find('012345', '23') == 2)\nassert(s.find('012345', '23', 1) == 2)\nassert(s.find('012345', '23', 1, 3) == -1)\nassert(s.find('012345', '23', 2, 4) == 2)\nassert(s.find('012345', '23', 3) == -1)\n\nassert(s.find('012345', '') == 0)\nassert(s.find('012345', '', 0, 0) == 0)\nassert(s.find('012345', '', 1) == 1)\nassert(s.find('012345', '', 1, 1) == 1)\nassert(s.find('012345', '', 1, 0) == -1)\nassert(s.find('012345', '', 6) == 6)\nassert(s.find('012345', '', 7) == -1)\n\nassert(s.count('012345', '') == 7)\nassert(s.count('012345', '', 2) == 5)\nassert(s.count('012345', '', 6) == 1)\n\nassert(s.count('121314', '1') == 3)\nassert(s.count('121314', '1', 1) == 2)\nassert(s.count('121314', '1', 2) == 2)\nassert(s.count('121314', '1', 1, 2) == 0)\nassert(s.count('121314', '1', 1, 3) == 1)\n\nassert(s.split('a b c d e f', '1') == ['a b c d e f'])\nassert(s.split('a b c d e f', ' ') == ['a', 'b', 'c', 'd', 'e', 'f'])\nassert(s.split('a b c d e f', ' ', 2) == ['a', 'b', 'c d e f'])\nassert(s.split('a b c d e f', '') == ['a b c d e f'])\n\nassert(s.format(\"%%\") == \"%\")\nassert(s.format(\"%i%%\", 12) == \"12%\")\nassert(s.format(\"%i%%%i\", 12, 13) == \"12%13\")\nassert(s.format(\"%s%%\", \"foo\") == \"foo%\")\nassert(s.format(\"%.1f%%\", 3.5) == \"3.5%\")\n"
        }
    },
    "berry-5": {
        "19": {
            "failing_info": "assert_failed: assert failed!\nstack traceback:\n\t<native>: in native function\n\ttests/suffix.be:25: in function `main`\n",
            "tc_code": "var keys = [ 'key1', 'key2', 'key3', 'key4' ]\nvar pairs = {\n    keys[0]: 'value1',\n    keys[1]: 'value2',\n    keys[2]: 'value3',\n    keys[3]: 'value4'\n}\n\nfor i : 0 .. keys.size() - 1\n    assert(pairs[keys[i]] == 'value' .. i + 1)\nend\n\n#- test cases related to #101 -#\nclass C var l end\nc=C()\nc.l=[0,1,2]\n\ndef t_101_nok_1() return c.l[0..1] end\ndef t_101_ok_1() var l2 = c.l return l2[0..1] end\n\nt_i = 0\ndef t_101_nok_2() return c.l[t_i] end\ndef t_101_ok_2() return c.l[0] end\n\nassert(t_101_nok_1() == [0, 1])\nassert(t_101_ok_1() == [0, 1])\nassert(t_101_nok_2() == 0)\nassert(t_101_ok_2() == 0)\n"
        }
    },
    "libucl-1": {
        "4": {
            "failing_info": "========================================\n   libucl 0.7.3: tests/test-suite.log\n========================================\n\n# TOTAL: 1\n# PASS:  0\n# SKIP:  0\n# XFAIL: 0\n# FAIL:  1\n# XPASS: 0\n# ERROR: 0\n\n.. contents:: :depth: 2\n\nFAIL: msgpack\n=============\n\nerror parsing input: too long or empty keytest_msgpack: test_msgpack.c:181: main: Assertion `0' failed.\nAborted\nFAIL msgpack.test (exit status: 134)\n\n",
            "tc_code": "if (!ucl_parser_add_chunk_full (parser, emitted, elen, 0,\n\t\t\t\tUCL_DUPLICATE_APPEND, UCL_PARSE_MSGPACK)) {\n\t\t\tfprintf (stderr, \"error parsing input: %s\",\n\t\t\t\t\tucl_parser_get_error (parser));\n\t\t\tassert (0);\n\t\t}"
        }
    },
    "libucl-2": {
        "1": {
            "failing_info": "========================================\n   libucl 0.7.3: tests/test-suite.log\n========================================\n\n# TOTAL: 1\n# PASS:  0\n# SKIP:  0\n# XFAIL: 0\n# FAIL:  1\n# XPASS: 0\n# ERROR: 0\n\n.. contents:: :depth: 2\n\nFAIL: basic\n===========\n\nFiles ../tests/basic.out and ../tests/basic/1.res are identical\nFiles ../tests/basic.out and ../tests/basic/11.res are identical\nFiles ../tests/basic.out and ../tests/basic/12.res are identical\nTest: ../tests/basic/13 failed, output:\nError occurred: error while parsing <unknown>: line: 4, column: 36 - 'macro arguments parsing error', character: '0x20'\nFAIL basic.test (exit status: 1)\n\n",
            "tc_code": "#!/bin/sh\n\nPROG=${TEST_BINARY_DIR}/test_basic\n\nfor _tin in ${TEST_DIR}/basic/*.in ; do\n\t_t=`echo $_tin | sed -e 's/.in$//'`\n\t_out=${TEST_OUT_DIR}/basic.out\n\t$PROG $_t.in $_out\n\tif [ $? -ne 0 ] ; then\n\t\techo \"Test: $_t failed, output:\"\n\t\tcat $_out\n\t\trm $_out\n\t\texit 1\n\tfi\n\tif [ -f $_t.res ] ; then\n\tdiff -s $_out $_t.res -u 2>/dev/null\n\t\tif [ $? -ne 0 ] ; then\n\t\t\trm $_out\n\t\t\techo \"Test: $_t output missmatch\"\n\t\t\texit 1\n\t\tfi\n\tfi\n\trm $_out\ndone\n\n\n"
        }
    },
    "libucl-3": {
        "1": {
            "failing_info": "========================================\n   libucl 0.7.2: tests/test-suite.log\n========================================\n\n# TOTAL: 1\n# PASS:  0\n# SKIP:  0\n# XFAIL: 0\n# FAIL:  1\n# XPASS: 0\n# ERROR: 0\n\n.. contents:: :depth: 2\n\nFAIL: basic\n===========\n\nFiles ../tests/basic.out and ../tests/basic/1.res are identical\nFiles ../tests/basic.out and ../tests/basic/11.res are identical\nFiles ../tests/basic.out and ../tests/basic/12.res are identical\nFiles ../tests/basic.out and ../tests/basic/13.res are identical\nTest: ../tests/basic/14 failed, output:\nError occurred: error while parsing <unknown>: line: 6, column: 1 - 'delimiter is missing', character: 'i'\nFAIL basic.test (exit status: 1)\n\n",
            "tc_code": "#!/bin/sh\n\nPROG=${TEST_BINARY_DIR}/test_basic\n\nfor _tin in ${TEST_DIR}/basic/*.in ; do\n\t_t=`echo $_tin | sed -e 's/.in$//'`\n\t_out=${TEST_OUT_DIR}/basic.out\n\t$PROG $_t.in $_out\n\tif [ $? -ne 0 ] ; then\n\t\techo \"Test: $_t failed, output:\"\n\t\tcat $_out\n\t\trm $_out\n\t\texit 1\n\tfi\n\tif [ -f $_t.res ] ; then\n\tdiff -s $_out $_t.res -u 2>/dev/null\n\t\tif [ $? -ne 0 ] ; then\n\t\t\trm $_out\n\t\t\techo \"Test: $_t output missmatch\"\n\t\t\texit 1\n\t\tfi\n\tfi\n\trm $_out\ndone\n\n\n"
        }
    },
    "libucl-4": {
        "1": {
            "failing_info": "========================================\n   libucl 0.5.0: tests/test-suite.log\n========================================\n\n# TOTAL: 1\n# PASS:  0\n# SKIP:  0\n# XFAIL: 0\n# FAIL:  1\n# XPASS: 0\n# ERROR: 0\n\n.. contents:: :depth: 2\n\nFAIL: basic\n===========\n\nFiles ../tests/basic.out and ../tests/basic/1.res are identical\nTest: ../tests/basic/11 failed, output:\nError occurred: error on line 3 at column 3: 'key must begin with a letter', character: '{'\nFAIL basic.test (exit status: 1)\n\n",
            "tc_code": "#!/bin/sh\n\nPROG=${TEST_BINARY_DIR}/test_basic\n\nfor _tin in ${TEST_DIR}/basic/*.in ; do\n\t_t=`echo $_tin | sed -e 's/.in$//'`\n\t_out=${TEST_OUT_DIR}/basic.out\n\t$PROG $_t.in $_out\n\tif [ $? -ne 0 ] ; then\n\t\techo \"Test: $_t failed, output:\"\n\t\tcat $_out\n\t\trm $_out\n\t\texit 1\n\tfi\n\tif [ -f $_t.res ] ; then\n\tdiff -s $_out $_t.res -u 2>/dev/null\n\t\tif [ $? -ne 0 ] ; then\n\t\t\trm $_out\n\t\t\techo \"Test: $_t output missmatch\"\n\t\t\texit 1\n\t\tfi\n\tfi\n\trm $_out\ndone\n\n\n"
        }
    },
    "libucl-5": {
        "1": {
            "failing_info": "========================================\n   libucl 0.7.2: tests/test-suite.log\n========================================\n\n# TOTAL: 1\n# PASS:  0\n# SKIP:  0\n# XFAIL: 0\n# FAIL:  1\n# XPASS: 0\n# ERROR: 0\n\n.. contents:: :depth: 2\n\nFAIL: basic\n===========\n\nFiles ../tests/basic.out and ../tests/basic/1.res are identical\nFiles ../tests/basic.out and ../tests/basic/11.res are identical\nFiles ../tests/basic.out and ../tests/basic/12.res are identical\nFiles ../tests/basic.out and ../tests/basic/13.res are identical\nTest: ../tests/basic/14 failed, output:\nError occurred: error while parsing <unknown>: line: 6, column: 1 - 'delimiter is missing', character: 'i'\nFAIL basic.test (exit status: 1)\n\n",
            "tc_code": "#!/bin/sh\n\nPROG=${TEST_BINARY_DIR}/test_basic\n\nfor _tin in ${TEST_DIR}/basic/*.in ; do\n\t_t=`echo $_tin | sed -e 's/.in$//'`\n\t_out=${TEST_OUT_DIR}/basic.out\n\t$PROG $_t.in $_out\n\tif [ $? -ne 0 ] ; then\n\t\techo \"Test: $_t failed, output:\"\n\t\tcat $_out\n\t\trm $_out\n\t\texit 1\n\tfi\n\tif [ -f $_t.res ] ; then\n\tdiff -s $_out $_t.res -u 2>/dev/null\n\t\tif [ $? -ne 0 ] ; then\n\t\t\trm $_out\n\t\t\techo \"Test: $_t output missmatch\"\n\t\t\texit 1\n\t\tfi\n\tfi\n\trm $_out\ndone\n\n\n"
        }
    },
    "libucl-6": {
        "1": {
            "failing_info": "========================================\n   libucl 0.5.0: tests/test-suite.log\n========================================\n\n# TOTAL: 1\n# PASS:  0\n# SKIP:  0\n# XFAIL: 0\n# FAIL:  1\n# XPASS: 0\n# ERROR: 0\n\n.. contents:: :depth: 2\n\nFAIL: basic\n===========\n\nFiles ../tests/basic.out and ../tests/basic/1.res are identical\nTest: ../tests/basic/11 failed, output:\nError occurred: error on line 3 at column 3: 'key must begin with a letter', character: '{'\nFAIL basic.test (exit status: 1)\n\n",
            "tc_code": "#!/bin/sh\n\nPROG=${TEST_BINARY_DIR}/test_basic\n\nfor _tin in ${TEST_DIR}/basic/*.in ; do\n\t_t=`echo $_tin | sed -e 's/.in$//'`\n\t_out=${TEST_OUT_DIR}/basic.out\n\t$PROG $_t.in $_out\n\tif [ $? -ne 0 ] ; then\n\t\techo \"Test: $_t failed, output:\"\n\t\tcat $_out\n\t\trm $_out\n\t\texit 1\n\tfi\n\tif [ -f $_t.res ] ; then\n\tdiff -s $_out $_t.res -u 2>/dev/null\n\t\tif [ $? -ne 0 ] ; then\n\t\t\trm $_out\n\t\t\techo \"Test: $_t output missmatch\"\n\t\t\texit 1\n\t\tfi\n\tfi\n\trm $_out\ndone\n\n\n"
        }
    }
}